招标文书
---

## 2.5 项目重点和难点

### 2.5.1 总体项目重点难点分析

#### 1．需求分析的难点

需求分析也称为软件需求分析、系统需求分析或需求分析工程等，是需求分析人员经过深入细致的调研和分析，准确理解用户和项目的功能、性能、可靠性等具体要求，将用户非形式的需求表述转化为完整的需求定义，从而确定系统必须做什么的过程。

需求分析是软件计划阶段的重要活动，也是软件生存周期中的一个重要环节，该阶段是分析系统在功能上需要“实现什么”，而不是考虑如何去“实现”。需求分析的目标是把用户对待开发软件提出的“要求”或“需要”进行分析与整理，确认后形成描述完整、清晰与规范的文档，确定软件需要实现哪些功能，完成哪些工作。此外，软件的一些非功能性需求(如软件性能、可靠性、响应时间、可扩展性等)，软件设计的约束条件，运行时与其他软件的关系等也是软件需求分析的目标。

需求分析阶段的工作,可以分为四个方面：问题识别、分析与综合、制订规格说明、评审。

- 问题识别：就是从系统角度来理解软件，确定对所开发系统的综合要求，并提出这些需求的实现条件，以及需求应该达到的标准。这些需求包括：功能需求(做什么)、性能需求(要达到什么指标)、环境需求(如机型、操作系统等)、可靠性需求(不发生故障的概率）、安全保密需求、用户界面需求、资源使用需求(软件运行是所需的内存、CPU等)、软件成本消耗与开发进度需求、预先估计以后系统可能达到的目标。
- 分析与综合： 逐步细化所有的软件功能，找出系统各元素间的联系，接口特性和设计上的限制，分析他们是否满足需求，剔除不合理部分，增加需要部分。最后综合成系统的解决方案，给出要开发的系统的详细逻辑模型(做什么的模型)。
- 制订规格说明书： 即编制文档，描述需求的文档称为软件需求规格说明书。请注意，需求分析阶段的成果是需求规格说明书，向下一阶段提交。
- 评审： 对功能的正确性，完整性和清晰性，以及其它需求给予评价。评审通过才可进行下一阶段的工作,否则重新进行需求分析

在产品推进过程中，需求分析的特点及难点，主要体现在以下几个方面

- 确定问题难。主要原因：一是应用领域的复杂性及业务变化，难以具体确定；二是用户需求所涉及的多因素引起的，比如运行环境和系统功能、性能、可靠性和接口等。
- 需求时常变化。软件的需求在整个软件生存周期，常会随着时间和业务而有所变化。有的用户需求经常变化，一些企业可能正处在体制改革与企业重组的变动期和成长期，其企业需求不成熟、不稳定和不规范，致使需求具有动态性。
- 交流难以达到共识。需求分析涉及的人事物及相关因素多，与用户、业务专家、需求工程师和项目管理员等进行交流时，不同的背景知识、角色和角度等，使交流共识较难。
- 获取的需求难以达到完备与一致。由于不同人员对系统的要求认识不尽相同，所以对问题的表述不够准确，各方面的需求还可能存在着矛盾。难以消除矛盾，形成完备和一致的定义。
- 需求难以进行深入的分析与完善。需求理解对不全面准确的分析，客户环境和业务流程的改变。市场趋势的变化等。也会随着分析、设计和实现而不断深入完善，可能在最后重新修订软件需求。分析人员应认识到需求变化的必然性，并采取措施减少需求变更对软件的影响。对必要的变更需求要经过认真评审、跟踪和比较分析后才能实施。

针对这些问题，采用以下措施

- 对项目背景进行分析
  - 谁提出了项目（高层）
  - 对项目的关键预期
  - 当前遗留系统（后续针对成本可指定利旧规则）
  - 业务假设（如业务量）
  - 技术假设（是否有技术选型要求）
- 对项目目标进行分析
  - 访谈项目干系人
  - 组织相关人员进行研讨（可采用头脑风暴）
  - 描述问题（针对研讨结果）
  - 分析问题（针对研讨结果）
- 干系人分析
  - 选择对业务了解，容易访谈的对象
  - 对关注点进行整理，识别调研中存在的冲突
- 项目约束分析
  - 进度约束（如领导视察）
  - 预算约束（可以直接问，也可以通过其经营规模、客户数量、历史同行投入推导）
  - 其他约束（法律法规、技术标准、社会文化等）
  - 资源支持（如场地等）
- 组建业务专家讨论组，成员有相关业务领导、行业资深专家、需求人员等

对于业务需求的调研注意以下几点

- 倾听：不要打断被调研对象，要让被调研对象按他们工作的场景进行需求的描述。开始时，由于需求分析人员有可能刚接触该领域，不要急着干预被调研对象，这样可以方便的得到原始需求。
- 问：问题不能太粗，要调动被调研者积极主动的提供业务需求，要全面了解正常流程下的业务开展情况，也要了解特殊场景下的流程，同时还要关注异常情况发生的场景。
- 反馈：通过手绘的草图与被调研对象确认需求是否正确，方便双方对需求的统一认识，还可以通过录音、笔记、原型设计工具等方式，进一步让被调研者确认需求。
- 及时沟通，特别是在项目早期，一定要在双方对项目需求达成共识；在项目进行中，也要定时（每天）进行沟通，及时了解项目进展。

#### 2．数据质量的难点

数据是信息时代的必然产物，数据质量的好坏直接影响到企业（医院）的生存能力和竞争力。如果数据质量不佳，便容易给企业（医院）带来以下危害：

- 干扰运营分析，影响决策；
- 影响算法模型质量，导致服务不够智能化；
- 耗费人力，实施方、开发人员、需求人员、各业务部分、IT人员、分析师等因为数据质量问题推倒工作重来；

数据质量评估。关于如何评估数据质量，业界有很多标准，这里主要从以下四个方面去评估：

- 完整性。数据的记录和信息是否完整。如字段信息是否完整、有没有因系统出问题而导致的数据丢失。
- 准确性。数据的记录是否正确。简单的如是否出现常识性错误（年龄大于200岁，男性做了妇科项目），电话号码、邮箱、ip等是否符合规范，枚举值是否正确等等。复杂一点的如基于维度的统计指标有没有问题，如平均值、总和、按照枚举值group by数据分布有没有异常等。
- 及时性。数据产出是否及时。数仓团队加工数据需要指定几点前必须产出并交给下游业务和相关分析人员。一般决策分析师需要分析前一日的数据(T+1)，如果数据隔几天才能看到，就会失去分析数据的价值。而某些业务甚至有小时级别以及实时的需求，及时性要求也就更高了。
- 一致性。数据库可能存在分支，同一份数据在不同地方需要保持一致；对于一些表的值可能参照另外一些表需要保持一致；数据库设计中需要保证一致性维度；对于表的字段类型以及值也需要保持一致（如地点写上海还是上海市，性别是f、m还是0、1标示等等）。

解决数据质量问题

- 保证数据的质量，首先，从数据库的建表开始，我们就要进行相关字段的约束。1）我们都知道数据库建表时，一般正常每个表都唯一的关键字段：Primary key主键，指能唯一标识一条记录的单个数据表列或联合的数据表列（联合主键|复合主键）。主键用到的数据表列数据不能包含空值。而且，一张表只能包含一个主键。确保我们创建表内容实体的完整性，保证被设置的列不会出现重复值。2）unique约束：除主键列外其他列各行数据不能重复时使用，其中表列可以包含空值。可以把unique唯一性约束放在一个或者多个列上，这些列或列的组合必须有唯一的。但不能包含主键列。保证实体完整性不出现重复值。3）Foreign key外键约束：外键用单个或多个字段作为外键。而外键约束就是引用字段必须在被引用字段中存在，除非引用字段部分为NULL或全部为NULL（由MATCH TYPE决定），否则INSERT或UPDATE时将返回失败，且被引用字段必须有唯一约束或是主键。作用主要是保证表与表之间的数据完整，即参照完整性。4）CHECK 约束：是指约束表中某一个或者某些列中可接受的数据值或者数据格式。例如我们在表中创建手机号码列时，要求输入11位数字时，就可以这样设定防止多输或少输数字。这个主要是我们自定义数据的完整性。5）default 默认值约束：这个主要是定义我们一些自动默认值可以减少用户工作量的同时，减少失误率的产生。这个也是我们自定义数据完整性的作用。当然我们在创建表时还包含众多规则也是保证我们数据的内容完整性等。
- 从系统设计层面考虑。完美的数据正确性有它的代价，不同的读写场景，对隔离性的需求不同。隔离性越高，数据越安全，但性能越低。业界一般会有四种隔离级别，按照不同隔离级别可能出现的 "症状" 划分：1）Read Uncommitted：可能读到他人未 Commit 、可能被 Rollback 的脏数据，即 Dirty Read；2）Read Committed：不会读到他人未 Commit 的数据，但事务内重复读一条数据，可能得到不同的结果，即 Non-repeatable Read；3）Repeatable Read：同一事务内重复读一条数据的结果相同，但读取多个数据的时候，可能会得到不同的结果，即 Phantom Read；4）Serializable：完全的隔离性，在语义上相当于事务的执行没有并发一样。对照以上级别，采用的开发框架也相应的定义了五种事务隔离级别:

  - TRANSACTION_NONE JDBC 驱动不支持事务
  - TRANSACTION_READ_UNCOMMITTED 允许脏读、不可重复读和幻读。
  - TRANSACTION_READ_COMMITTED 禁止脏读，但允许不可重复读和幻读。
  - TRANSACTION_REPEATABLE_READ 禁止脏读和不可重复读，单运行幻读。
  - TRANSACTION_SERIALIZABLE 禁止脏读、不可重复读和幻读。

  隔离级别越高，意味着数据库事务并发执行性能越差，能处理的操作就越少。可以通过conn.setTransactionLevel去设置需要的隔离级别。JDBC规范虽然定义了事务的以上支持行为，但是各个JDBC驱动，数据库厂商对事务的支持程度可能各不相同。出于性能的考虑我们一般设置TRANSACTION_READ_COMMITTED就差不多了，剩下的通过使用数据库的锁来帮我们处理别的。

- 保证数据的准确性，另一重要手段就是必须采用国家标准、行业标准。在目前形势下，国家在搭建统一大健康大数据医疗平台，发布了很多医疗行业接口标准和国家级数据字典，这些标准正是我们搭建系统的基础。严格执行国家和行业相关标准和程序，符合业务应用技术标准和管理规范，做到标准统一、术语规范、内容准确，保证服务和管理对象在系统中身份标识唯一、基本数据项一致，所采集的信息应当严格实行信息复核终审程序，做好数据质量管理。
- 建立严格的电子实名认证和数据访问控制，规范数据接入、使用和销毁过程的痕迹管理，确保数据访问行为可管、可控及服务管理全程留痕，可查询、可追溯，对任何数据泄密泄露事故及风险可追溯到相关责任单位和责任人。
- 采取数据分类、重要数据备份、加密认证等措施保障数据安全。应当建立可靠的数据容灾备份工作机制，定期进行备份和恢复检测，确保数据能够及时、完整、准确恢复，实现长期保存和历史数据的归档管理。
- 应当依法依规使用医疗数据有关信息，提供安全的信息查询和复制渠道，确保公民隐私保护和数据安全。

#### 3．运行性能的难点

服务端性能的保障，需从架构设计时进行考量，选择合理的架构才能保证高性能的服务。面向服务的架构（SOA）是一个组件模型，它将应用程序的不同功能单元（称为服务）进行拆分，并通过这些服务之间定义良好的接口和契约联系起来。接口是采用中立的方式进行定义的，它应该独立于实现服务的硬件平台、操作系统和编程语言。这使得构建在各种各样的系统中的服务可以以一种统一和通用的方式进行交互。服务与服务间采用轻量级的通信机制互相沟通（通常是基于HTTP的RESTful API）。

SOA 架构主要优势

- SOA可通过互联网服务器发布，从而突破企业内网的限制，实现与供应链上下游伙伴业务的紧密结合。通过SOA架构，企业可以与其业务伙伴直接建立新渠道，建立新伙伴的成本得以降低。
- SOA与平台无关，减少了业务应用实现的限制。要将企业的业务伙伴整合到企业的“大”业务系统中，对其业务伙伴具体采用什么技术没有限制。
- SOA具有低耦合性特点，业务伙伴对整个业务系统的影响较低。在企业与各业务伙伴关系不断发生变化的情况下，节省的费用会越来越多。
- SOA具有可按模块分阶段进行实施的优势。可以成功一步再做下一步，将实施对企业的冲击减少到最小。
- SOA的实施可能并不具有成本显著性。这要分三种情况加以讨论：
  - 当企业从零开始构建业务系统时，采用SOA架构与不采用SOA架构成本可看做是相同的。
  - 当企业业务发展或发生企业重组等变化而原有系统不能满足需要，而需要重构业务系统时，采用SOA架构与不采用SOA架构成本可看做是相同的。
  - 当企业业务发生缓慢变化并可预见到将来需要重构业务系统时，由于可以按模块分阶段逐步实施SOA以适应变化的需要，这样企业不需一下投入一大笔经费进行系统改造，而是根据企业业务发展情况和资金情况逐步投入，缓解了信息投入的压力。

系统设计时需考虑以下几个重要环节

- 高并发的应用缓存

  磁盘缓存。即缓存数据存储在磁道上，在JVM重启时数据还存在的，而堆缓存/堆外缓存数据会丢失，需要重新加载。有Ehcache 3.x、MapDB实现。

  分布式缓存。进程内缓存和磁盘缓存，在多JVM实例的情况下，会存在两个问题：1、单机容量问题；2、数据一致性问题（多台JVM实例的缓存数据不一致怎么办？），这个问题不用纠结，既然数据允许缓存，则表示允许一定时间内的不一致，因此可以设置缓存数据的过期时间来定期更新数据；3、缓存不命中时，需要回源到DB/服务请求多变问题：每个实例在缓存不命中的情况下都会回源到DB加载数据，因此多实例后DB整体的访问量变多了解决办法是可以使用如一致性哈希分片算法。因此，这些情况可以考虑使用分布式缓存来解决。

  可以使用ehcache–clustered 实现JAVA进程间分布式缓存。最好的办法是使用redis实现分布式缓存。

- HTTP缓存

  浏览器缓存是指当我们使用浏览器访问一些网站页面或者http服务时，根据服务端返回的缓存设置响应头将响应内容缓存到浏览器，下次可以直接使用缓存内容或者仅需要去服务端验证内容是否过期即可。这样的好处可以减少浏览器和服务端之间来回传输的数据量，节省带宽提升性能。

  解决办法：内容不需要动态（计算、渲染等）速度更快，内容越接近于用户速度越快。像apache traffic server、squid、varnish、nginx等技术都可以来进行内容缓存。还有CDN就是用来加速用户访问的。

- 对象池化

  在应用系统开发过程中，我们经常会用到池化技术，如对象池、连接池、线程池等，通过池化来减少一些消耗，以提升性能。对象池通过复用对象从而减少创建对象、垃圾回收 的开销。但是，池化不能太大，太大会影响GC时的扫描时间。连接池如数据库连接池、Redis连接池、Http连接池，通过复用TCP连接减少创建和释放连接的时间来提升性能。线程池也是类似的，通过复用线程提升性能。也就是说池化的目的就是通过复用技术提升性能。

- 扩容

  读写分离：当数据库访问量还不是很大的时候，我们可以适当增加服务器，数据库主从复制的方式将读写分离

  垂直分区：当写入操作一旦增加的时候，那么主从数据库将花更多的时间的放在数据同步上，这个时候服务器也是不堪重负的；那么就有了数据的垂直分区，数据的垂直分区思路是将写入操作比较频繁的数据表，如用户表_user,或者订单表_orders,那么我们就可以把这个两个表分离出来，放在不同的服务器，如果这两个表和其他表存在联表查询，那么就只能把原来的sql语句给拆分了，先查询一个表，在查询另一个，虽然说这个会消耗更过性能，但比起那种大量数据同步，负担还是减轻了不少；

  水平分区：但是往往事情不尽人意，可能采取垂直分区能撑一段时间，由于业务增长，一下子蹦到了1000w,这个时候可以采取数据的进行分离，我们可以根据user的Id不同进行分配，如采取%2、 形式，当然这种形式对以后的扩展有了很大的限制，当我由10个分区增加到20个的时候，所有的数据都得重新分区，那么将是一个的很庞大的计算量；几种常见的算法： 哈希算法：就是采用user_id%的方式; 范围：可以根据user_id字符值范围分区，如1-1000为一区，1001-2000则是另一个区等； 映射关系：就是将user_id存在的所对应的分区放在数据库中保存，当用户操作时先去查询所在分区，再进行操作.

服务部署时考虑以下措施

- 负载均衡

  负载均衡建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。

  负载均衡的意义在于，让所有节点以最小的代价、最好的状态对外提供服务，这样系统吞吐量最大，性能更高，对于用户而言请求的时间也更小。而且，负载均衡增强了系统的可靠性，最大化降低了单个节点过载、甚至crash的概率。不难想象，如果一个系统绝大部分请求都落在同一个节点上，那么这些请求响应时间都很慢，而且万一节点降级或者崩溃，那么所有请求又会转移到下一个节点，造成雪崩。

  负载均衡器将传入的请求分发到应用服务器和数据库等计算资源。无论哪种情况，负载均衡器将从计算资源来的响应返回给恰当的客户端。负载均衡器的效用在于:

  - 防止请求进入不好的服务器
  - 防止资源过载
  - 帮助消除单一的故障点

  负载均衡器可以通过硬件（昂贵）或 HAProxy 等软件来实现

  通常会设置采用工作─备用 或 双工作 模式的多个负载均衡器，以免发生故障。

  负载均衡器能基于多种方式来实现路由流量:
  - Random LoadBalance 随机，按权重设置随机概率。随机选择指的是从已有的后端列表中随机选择一个节点出来提供服务。 一种随机选择的方法是把所有的节点看做一个一个的点，并把这些点连起来排成一条直线， 随机选择就是在这条直线上随机选择一个点。至于怎么做随机选择一个点，这个可以用各个编程语言官方实现自带的生成 指定区间（直线的开始到结尾区间）内的随机数的方法来生成一个随机数的方式来选择对应的点。实际使用中各个节点往往都带有不同的权重，即虽然是随机选择但是期望不同权重的节点被选择的几率不一样， 权重高的被选中的几率大，权重低的被选中的几率小。
  - Session/cookie。Session保持（会话保持）是我们见到最多的名词之一，通过会话保持，负载均衡进行请求分发的时候保证每个客户端固定的访问到后端的同一台应用服务器。会话保持方案在所有的负载均衡都有对应的实现。而且这是在负载均衡这一层就可以解决Session问题。对于Nginx可以选用Session保持的方法实行负载均衡，nginx的upstream目前支持5种方式的分配方式，其中有两种比较通用的Session解决方法，ip_hash和url_hash。但会话保持的缺点也是明显的：会话保持看似解决了Session同步的问题，但是却带来的一些其它方面的问题，负载不均衡了，由于使用了Session保持，很显然就无法保证负载绝对的均衡。没有彻底解决问题：如果后端有服务器宕机，那么这台服务器的Session丢失，被分配到这台服务请求的用户还是需要重新登录。
  - 轮询调度或加权轮询调度算法。简单做法，提供同质服务的节点逐个对外提供服务，这样能做到绝对的均衡，可以看到，所有的节点都是以同样的概率提供服务，即没有考虑到节点的差异，也许同样数目的请求。加权轮训算法就是在轮训算法的基础上，考虑到机器的差异性，分配给机器不同的权重，能者多劳。注意，这个权重的分配依赖于请求的类型，比如计算密集型，那就考虑CPU、内存；如果是IO密集型，那就考虑磁盘性能。
  - 四层负载均衡。四层负载均衡根据监看传输层的信息来决定如何分发请求。通常，这会涉及来源，目标 IP 地址和请求头中的端口，但不包括数据包（报文）内容。四层负载均衡执行网络地址转换（NAT）来向上游服务器转发网络数据包。
  - 七层负载均衡。七层负载均衡器根据监控应用层来决定怎样分发请求。这会涉及请求头的内容，消息和 cookie。七层负载均衡器终结网络流量，读取消息，做出负载均衡判定，然后传送给特定服务器。比如，一个七层负载均衡器能直接将视频流量连接到托管视频的服务器，同时将更敏感的用户账单流量引导到安全性更强的服务器。

- HAProxy

  HAProxy 是一个免费的负载均衡软件，可以运行于大部分主流的 Linux 操作系统上。HAProxy 特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。HAProxy运行在当前的硬件上，完全可以支持数以万计的并发连接。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中， 同时可以保护你的web服务器不被暴露到网络上。

  Nginx、HAProxy 是目前使用最为广泛的负载均衡软件一般对负载均衡的使用是随着网站规模的提升，根据不同阶段使用不同技术，如果是中小型Web应用，日PV小于1000万，Nginx足以，大型网站以及重要的服务，且服务器较多时，可考虑用 HAProxy。

- 方案对比

  - Nginx 优点

    - 工作在网络7层之上，可针对http应用做一些分流的策略，如针对域名、目录结构，它的正规规则比HAProxy更为强大和灵活，所以，目前为止广泛流行。
    - Nginx对网络稳定性的依赖非常小，理论上能ping通就能进行负载功能。
    - Nginx安装与配置比较简单，测试也比较方便，基本能把错误日志打印出来。
    - 可以承担高负载压力且稳定，硬件不差的情况下一般能支撑几万次的并发量。
    - Nginx可以通过端口检测到服务器内部的故障，如根据服务器处理网页返回的状态码、超时等，并会把返回错误的请求重新提交到另一个节点。
    - 不仅仅是优秀的负载均衡器/反向代理软件，同时也是强大的Web应用服务器
    - 可作为中层反向代理使用。
    - 可作为静态网页和图片服务器。
    - Nginx社区活跃，第三方模块非常多，相关的资料在网上比比皆是。

  - Nginx 缺点

    - 适应范围较小，仅能支持http、https、Email协议。
    - 对后端服务器的健康检查，只支持通过端口检测，不支持url来检测。比如用户正在上传一个文件，而处理该上传的节点刚好在上传过程中出现故障，Nginx会把上传切到另一台服务器重新处理，而LVS就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，用户可能会因此而不满。

  - HAProxy优点

    - HAProxy是支持虚拟主机的，可以工作在4、7层(支持多网段)
    - HAProxy的优点能够补充Nginx的一些缺点，比如支持Session的保持，Cookie的引导；同时支持通过获取指定的url来检测后端服务器的状态。
    - HAProxy跟LVS类似，本身就只是一款负载均衡软件；单纯从效率上来讲HAProxy会比Nginx有更出色的负载均衡速度，在并发处理上也是优于Nginx的。
    - HAProxy支持TCP协议的负载均衡转发
    - HAProxy负载均衡策略非常多，HAProxy的负载均衡算法现在具体有如下8种
      - roundrobin。表示简单的轮询，每个服务器根据权重轮流使用，在服务器的处理时间平均分配的情况下这是最流畅和公平的算法。该算法是动态的，对于实例启动慢的服务器权重会在运行中调整。最大支持4095个后端主机；
      - leastconn。连接数最少的服务器优先接收连接。leastconn建议用于长会话服务，例如LDAP、SQL、TSE等，而不适合短会话协议。如HTTP.该算法是动态的，对于实例启动慢的服务器权重会在运行中调整。
      - static-rr。每个服务器根据权重轮流使用，类似roundrobin，但它是静态的，意味着运行时修改权限是无效的。另外，它对服务器的数量没有限制。该算法一般不用；
      - source。对请求源IP地址进行哈希，用可用服务器的权重总数除以哈希值，根据结果进行分配。只要服务器正常，同一个客户端IP地址总是访问同一个服务器。如果哈希的结果随可用服务器数量而变化，那么客户端会定向到不同的服务器；该算法一般用于不能插入cookie的Tcp模式。它还可以用于广域网上为拒绝使用会话cookie的客户端提供最有效的粘连；该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。
      - uri。表示根据请求的URI左端（问号之前）进行哈希，用可用服务器的权重总数除以哈希值，根据结果进行分配。只要服务器正常，同一个URI地址总是访问同一个服务器。一般用于代理缓存和反病毒代理，以最大限度的提高缓存的命中率。该算法只能用于HTTP后端；该算法一般用于后端是缓存服务器；该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。
      - url_param。在HTTP GET请求的查询串中查找<param>中指定的URL参数，基本上可以锁定使用特制的URL到特定的负载均衡器节点的要求；该算法一般用于将同一个用户的信息发送到同一个后端服务器；该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。
      - hdr(name)。在每个HTTP请求中查找HTTP头<name>，HTTP头<name>将被看作在每个HTTP请求，并针对特定的节点；如果缺少头或者头没有任何值，则用roundrobin代替；该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。
      - rdp-cookie（name）。为每个进来的TCP请求查询并哈希RDP cookie<name>；该机制用于退化的持久模式，可以使同一个用户或者同一个会话ID总是发送给同一台服务器。如果没有cookie，则使用roundrobin算法代替；该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。

  - HAPorxy缺点：

    - 不支持POP/SMTP协议
    - 不支持SPDY协议
    - 不支持HTTP cache功能。现在不少开源的lb项目，都或多或少具备HTTP cache功能。
    - 重载配置的功能需要重启进程，虽然也是soft restart，但没有Nginx的reaload更为平滑和友好。
    - 多进程模式支持不够好。

- 反向代理

  <img src="demo/反向代理.png"/>

  反向代理是一种可以集中地调用内部服务，并提供统一接口给公共客户的 web 服务器。来自客户端的请求先被反向代理服务器转发到可响应请求的服务器，然后代理再把服务器的响应结果返回给客户端。

  带来的好处包括：
  - 增加安全性 - 隐藏后端服务器的信息，屏蔽黑名单中的 IP，限制每个客户端的连接数。
  - 提高可扩展性和灵活性 - 客户端只能看到反向代理服务器的 IP，这使你可以增减服务器或者修改它们的配置。
  - 本地终结 SSL 会话 - 解密传入请求，加密服务器响应，这样后端服务器就不必完成这些潜在的高成本的操作。
  - 免除了在每个服务器上安装 X.509 证书的需要
  - 压缩 - 压缩服务器响应
  - 缓存 - 直接返回命中的缓存结果
  - 静态内容 - 直接提供静态内容
    - HTML/CSS/JS
    - 图片
    - 视频
    - 其他资源

- 负载均衡器与反向代理

  - 当你有多个服务器时，部署负载均衡器非常有用。通常，负载均衡器将流量路由给一组功能相同的服务器上。
  - 即使只有一台 web 服务器或者应用服务器时，反向代理也有用，可以参考上一节介绍的好处。
  - NGINX 和 HAProxy 等解决方案可以同时支持第七层反向代理和负载均衡。

  不利之处：
  - 引入反向代理会增加系统的复杂度。
  - 单独一个反向代理服务器仍可能发生单点故障，配置多台反向代理服务器（如故障转移）会进一步增加复杂度。

- 网关

  <img src="demo/网关.png"/>

  - 黑白名单。黑名单启用后，被列入到黑名单的用户（或IP地址、IP包）不能通过。如果设立了白名单，则在白名单中的用户（或IP地址、IP包）会优先通过，安全性和快捷性都大大提高。将其含义扩展一步，那么凡有黑名单功能的应用，就会有白名单功能与其对应。
  - 防爬控制。网络爬虫（又被称为网页蜘蛛，网络机器人），是一种按照一定的规则，自动地抓取网络信息的程序或者脚本。另外一些不常使用的名字还有蚂蚁、自动索引、模拟程序或者蠕虫。系统从自身的安全和服务性能考虑，会设置防爬策略，如采用 Nginx 层面的限流。
  - 安全控制。
  - 权限控制。对用户访问资源进行权限分配。
  - 缓存。提高服务高并发，需采用缓存技术对只读信息进行缓存。
  - 请求限流。为了防止服务意外暴增的访问、攻击等，导致整个系统瘫痪，在前后端接口服务处进行流量限制是非常有必要的。可以根据不同场景配置多个不同的限制，比如授权某个IP每秒、每分钟、每小时、每天、每周的最大调用次数。 这些限制策略可以配置在所有请求上，也可以单独给每个API接口去配置。1）基于IP全局限流，限制来自同IP请求的最大次数。如果在一分钟内，同样IP的客户端分别调用api/values和api/values/1两个接口， 那么调用api/values/1的请求会被拒绝掉。2）基于IP的端点限流，上面的api/values限流配置会对整个api/values开头的API限流，同一秒内、同一ip访问api/values后，所有后续访问api/values/xxx的请求都会被拒绝掉。 如果配置了端点限流，同一秒内你也访问api/values/1了，请求将不会被拒绝，因为它们走的是不同的路由。3）基于IP和客户端key的端点限流，如果同一个ip的客户端，在同一秒内，调用了2次api/values，其最后一次的调用将会被拒绝掉。如果想接口通过唯一key去识别限制客户端，忽略客户端的ip地址限制，应该配置相应的key。4）IP和客户端key的白名单，如果请求是从一个白名单中的IP或客户端key发起的，那么限流策略将不会生效，这个请求的所有信息也不会被存储。 其IP白名单列表支持IP v4和v6的范围配置，比如"192.168.0.0/24", "fe80::/10" 和 "192.168.0.0-192.168.0.255"。5）IP和客户端key自定义限制频率，可以自定义基于ip或客户端key的请求频率限制
  - 熔断降级。除了流量控制以外，对调用链路中不稳定的资源进行熔断降级也是保障高可用的重要措施之一。由于调用关系的复杂性，如果调用链路中的某个资源不稳定，最终会导致请求发生堆积。熔断降级会在调用链路中某个资源出现不稳定状态时（例如调用超时或异常比例升高），对这个资源的调用进行限制，让请求快速失败，避免影响到其它的资源而导致级联错误。当资源被降级后，在接下来的降级时间之内，对该资源的调用都自动熔断（默认行为是抛出 DegradeException）。
  - 调用服务。访问业务服务。
  - 记录日志。对整个访问过程进行日志记录，方便系统管理员进行性能统计。

- 服务运行监控

  服务器的健康状况监控，是系统正常运行的保障，主要要对以下指标进行监控：

  - CPU(Load) CPU使用率/负载。机器的CPU占有率越高，说明机器处理越忙，运算型任务越多。一个任务可能不仅会有运算部分，还会有I/O(磁盘I/O与网络I/O)部分，当在处理I/O时，时间片未完其CPU也会释放，因此某个时间点的CPU占有率没有太大的意义，因此需要计算一段时间内的平均值，那么平均负载(Load Average)这个指标便能很好得对其进行表征。平均负载：它是根据一段时间内占有CPU的进程数目和等待CPU的进程数目计算出来的，其中等待CPU的进程不包括处于wait状态的进程，比如在等待I/O的进程，即指那些就绪状态的进程，运行只缺CPU这个资源。
  - Memory 内存。内存也是系统运行性能的一个很重要的指标，如果一个机器内存不足，那么将会导致进程运行异常而退出。如果进程发生内存泄漏，则会导致大量内存被浪费而无足够可用内存。内存监控一般包括total(机器总内存)、free(机器可用内存)、swap(交换区大小)、cache(缓存大小)等。
  - Disk 磁盘空间。机器的磁盘空间也是一个重要的指标，一旦使用率超过阈值而使得可用不足，那么就需要进行扩容或者清除一些无用的文件。
  - Disk I/O 磁盘I/O。机器的磁盘空间也是一个重要的指标，一旦磁盘I/O过重，那么说明运行的进程在大量的文件读写并且cache命中率低。那么一个简单的方法便是增大文件缓存大小来提高命中率从而降低I/O。
  - Network I/O 网络I/O。如果服务器网络连接过多，那么会造成大量的数据包在缓冲区长时间得不到处理，一旦缓冲区不足，便会造成数据包丢失问题，对于TCP，数据包丢失便会进行重传，这有会导致大量的重传；对于UDP，数据包丢失不会进行重传，那么数据便会丢失。因此，服务器的网络连接不宜过多，需要进行监控。 服务器一般接收UDP与TCP请求，都是无状态连接，TCP(传输控制协议)是一种提供可靠的数据传输协议，UDP(用户数据报协议)是一种面向无连接的协议，即其传输简单但不可靠。
  - Connect Num 连接数。对于每一台服务器，都应该限制同时连接数，但是这个阈值又不好确定，因此当监测到系统负载过重时，然后取其连接数，这个值便可作为参考值。
  - File Handle Num 文件句柄数。文件句柄数即当前打开的文件数，对于linux，系统默认支持的最大句柄数是1024，当然每个系统可以不一样，也可以修改，最大不能超过无符号整型最大值(65535)，可以使用ulimit -n命令进行查看，即因此如果同时打开的文件数超过这个数便会发生异常。因此这个指标也需要进行监控。

  推荐采用开源监控方案 Prometheus + Grafana + Alertmanager。

  <img src="demo/dashboard.png"/>

  Prometheus是一套开源的监控&报警&时间序列数据库的组合

  - 非常少的外部依赖，安装使用超简单
  - 已经有非常多的系统集成 例如：docker HAProxy Nginx JMX等等
  - 服务自动化发现
  - 直接集成到代码
  - 设计思想是按照分布式、微服务架构来实现的
  - 自定义多维度的数据模型
  - 非常高效的存储 平均一个采样数据占 ~3.5 bytes左右，320万的时间序列，每30秒采样，保持60天，消耗磁盘大概228G。
  - 强大的查询语句
  - 轻松实现数据可视化

  Grafana是一个跨平台的开源的度量分析和可视化工具，可以通过将采集的数据查询然后可视化的展示，并及时通知。它主要有以下六大特点：

  - 展示方式：快速灵活的客户端图表，面板插件有许多不同方式的可视化指标和日志，官方库中具有丰富的仪表盘插件，比如热图、折线图、图表等多种展示方式；
  - 数据源：Graphite，InfluxDB，OpenTSDB，Prometheus，Elasticsearch，CloudWatch和KairosDB等；
  - 通知提醒：以可视方式定义最重要指标的警报规则，Grafana将不断计算并发送通知，在数据达到阈值时通过Slack、PagerDuty等获得通知；
  - 混合展示：在同一图表中混合使用不同的数据源，可以基于每个查询指定数据源，甚至自定义数据源；
  - 注释：使用来自不同数据源的丰富事件注释图表，将鼠标悬停在事件上会显示完整的事件元数据和标记；
  - 过滤器：Ad-hoc过滤器允许动态创建新的键/值过滤器，这些过滤器会自动应用于使用该数据源的所有查询。

  Alertmanager 处理由例如 Prometheus 服务器等客户端发来的警报。它负责删除重复数据、分组，并将警报通过路由发送到正确的接收器，比如电子邮件、Slack等。Alertmanager还支持groups,silencing和警报抑制的机制。

  综合以上工具，一旦发现异常信息和性能超标，那么马上发送邮件给管理员，也可以使用云监控push给管理员的云账号。

客户端性能，主要针对 Windows 平台

- 禁用某些视觉效果可以提高性能。
- 禁用或设置不需要的服务手册，默认情况下，某些进程会影响系统CPU和内存的运行速率。

  - 1.按Windows键+R键，键入services.msc后按回车，打开“服务”窗口；
  - 2.选择不需要的服务，右键单击设置为“手动”或“禁用”的项；
  - 3.如果某一项为“启动”，先手动“停止”后再右键打开属性设置为“手动”；
  - 4.完成后，可以关闭窗口。
- 某些程序设置的是开机启动，这些开机自启的程序或是由用户设置，或是软件私自设置，可以进行设置来降低系统的额外消耗；

  - 1.按Windows键+R，键入msconfig后按回车，打开系统设置窗口；
  - 2.在窗口中选择“启动”项，禁用未知的启动项即可。
  - 3.禁用进城后点击“应用”并“确定”。
- 系统中“写入缓存”若是关闭状态，是会影响系统性能的，若打开将有助于系统性能的提升，加快系统的运行，但是缺点是比较担心断电（断电后会导致尚未写入的数据可能存在丢失的风险），所以一定要在不断电的情况下使用此功能。

  - 1.按Windows键+Pause键（位于键盘右上角），弹出“系统”窗口；
  - 2.在出现的系统窗口左侧单击“设备管理器”，出现的窗口中展开“磁盘驱动器”；
  - 3.下拉列表将显示硬盘驱动器，右键单击并选择属性，单击“设备属性”中“策略”选项卡；
  - 4.选中“在设备上启用写入缓存”旁边的框，即可，也可以选择关闭设备。
- 临时文件、下载文件、回收站文件、注册表垃圾及磁盘中的碎片会加重系统运行负担，进行清理硬盘垃圾、执行磁盘碎片整理，能够帮助系统提升运行速度（这也是为什么说重装系统会使电脑的运行速度加快了）。
  - 1.打开wisecare365进行电脑“一键扫描”，并“修复”；
  - 2.选择“系统清理”选项中的各个项目逐一“清理”和“扫描”；
  - 3.选择“系统优化”中的“磁盘整理”、“注册表整理”进行优化和整理；
  - 4.双击桌面“漂浮球”进行虚拟内存的释放，可减少因为虚拟内存而产生的内存消耗（而导致的系统运行过慢）。

#### 4．数据安全的难点

信息安全或数据安全有两方面的含义：一是数据本身的安全，主要是指采用现代密码算法对数据进行主动保护，如数据保密、数据完整性、双向强身份认证等，二是数据防护的安全，主要是采用现代信息存储手段对数据进行主动防护，如通过磁盘阵列、数据备份、异地容灾等手段保证数据的安全。

在系统整体规划时，根据《信息系统安全等级保护要求》第三级，设计了完全符合安全等级要求的系统。

在数据保护方面主要有以下安全措施:

- 网络安全
  - 结构安全
    - 应保证主要网络设备的业务处理能力具备冗余空间，满足业务高峰期需要；
    - 应保证网络各个部分的带宽满足业务高峰期需要；
    - 应在业务终端与业务服务器之间进行路由控制建立安全的访问路径；
    - 应绘制与当前运行情况相符的网络拓扑结构图；
    - 应根据各部门的工作职能、重要性和所涉及信息的重要程度等因素，划分不同的子网或网段，并按照方便管理和控制的原则为各子网、网段分配地址段；
    - 应避免将重要网段部署在网络边界处且直接连接外部信息系统，重要网段与其他网段之间采取可靠的技术隔离手段；
    - 应按照对业务服务的重要次序来指定带宽分配优先级别，保证在网络发生拥堵的时候优先保护重要主机。

  - 访问控制
    - 应在网络边界部署访问控制设备，启用访问控制功能；
    - 应能根据会话状态信息为数据流提供明确的允许/拒绝访问的能力，控制粒度为端口级；
    - 应对进出网络的信息内容进行过滤，实现对应用层HTTP、FTP、TELNET、SMTP、POP3等协议命令级的控制；
    - 应在会话处于非活跃一定时间或会话结束后终止网络连接；
    - 应限制网络最大流量数及网络连接数；
    - 重要网段应采取技术手段防止地址欺骗；
    - 应按用户和系统之间的允许访问规则，决定允许或拒绝用户对受控系统进行资源访问，控制粒度为单个用户；
    - 应限制具有拨号访问权限的用户数量。

  - 安全审计
    - 应对网络系统中的网络设备运行状况、网络流量、用户行为等进行日志记录；
    - 审计记录应包括：事件的日期和时间、用户、事件类型、事件是否成功及其他与审计相关的信息；
    - 应能够根据记录数据进行分析，并生成审计报表；
    - 应对审计记录进行保护，避免受到未预期的删除、修改或覆盖等。
  - 边界完整性检查
    - 应能够对非授权设备私自联到内部网络的行为进行检查，准确定出位置，并对其进行有效阻断；
    - 应能够对内部网络用户私自联到外部网络的行为进行检查，准确定出位置，并对其进行有效阻断。
  - 入侵防范
    - 应在网络边界处监视以下攻击行为：端口扫描、强力攻击、木马后门攻击、拒绝服务攻击、缓冲区溢出攻击、IP碎片攻击和网络蠕虫攻击等；
    - 当检测到攻击行为时，记录攻击源IP、攻击类型、攻击目的、攻击时间，在发生严重入侵事件时应提供报警。
  - 恶意代码防范
    - 应在网络边界处对恶意代码进行检测和清除；
    - 应维护恶意代码库的升级和检测系统的更新
  - 网络设备防护
    - 应对登录网络设备的用户进行身份鉴别；
    - 应对网络设备的管理员登录地址进行限制；
    - 网络设备用户的标识应唯一；
    - 主要网络设备应对同一用户选择两种或两种以上组合的鉴别技术来进行身份鉴别；
    - 身份鉴别信息应具有不易被冒用的特点，口令应有复杂度要求并定期更换；
    - 应具有登录失败处理功能，可采取结束会话、限制非法登录次数和当网络登录连接超时自动退出等措施；
    - 当对网络设备进行远程管理时，应采取必要措施防止鉴别信息在网络传输过程中被窃听；
    - 应实现设备特权用户的权限分离。

- 服务器操作系统
  - 身份鉴别
    - 应对登录操作系统和数据库系统的用户进行身份标识和鉴别；
    - 操作系统和数据库系统管理用户身份标识应具有不易被冒用的特点，口令应有复杂度要求（最少8位长度，数字大小写字母特殊符合混合使用）并定期更换（半年）；
    - 应启用登录失败处理功能，可采取结束会话、限制非法登录次数和自动退出等措施；
    - 当对服务器进行远程管理时，应采取必要措施，防止鉴别信息在网络传输过程中被窃听；
    - 应为操作系统和数据库系统的不同用户分配不同的用户名，确保用户名具有唯一性。
    - 应采用两种或两种以上组合的鉴别技术对管理用户进行身份鉴别。
  - 访问控制
    - 应启用访问控制功能，依据安全策略控制用户对资源的访问；
    - 应根据管理用户的角色分配权限，实现管理用户的权限分离，仅授予管理用户所需的最小权限；
    - 应实现操作系统和数据库系统特权用户的权限分离；
    - 应严格限制默认帐户的访问权限，重命名系统默认帐户，修改这些帐户的默认口令；
    - 应及时删除多余的、过期的帐户，避免共享帐户的存在。
    - 应对重要信息资源设置敏感标记；
    - 应依据安全策略严格控制用户对有敏感标记重要信息资源的操作；
  - 安全审计
    - 审计范围应覆盖到服务器和重要客户端上的每个操作系统用户和数据库用户；
    - 审计内容应包括重要用户行为、系统资源的异常使用和重要系统命令的使用等系统内重要的安全相关事件；
    - 审计记录应包括事件的日期、时间、类型、主体标识、客体标识和结果等；
    - 应能够根据记录数据进行分析，并生成审计报表；
    - 应保护审计进程，避免受到未预期的中断；
    - 应保护审计记录，避免受到未预期的删除、修改或覆盖等。
  - 剩余信息保护
    - 应保证操作系统和数据库系统用户的鉴别信息所在的存储空间，被释放或再分配给其他用户前得到完全清除，无论这些信息是存放在硬盘上还是在内存中；
    - 应确保系统内的文件、目录和数据库记录等资源所在的存储空间，被释放或重新分配给其他用户前得到完全清除。
  - 入侵防范
    - 应能够检测到对重要服务器进行入侵的行为，能够记录入侵的源IP、攻击的类型、攻击的目的、攻击的时间，并在发生严重入侵事件时提供报警；
    - 应能够对重要程序的完整性进行检测，并在检测到完整性受到破坏后具有恢复的措施；
    - 操作系统应遵循最小安装的原则，仅安装需要的组件和应用程序，并通过设置升级服务器等方式保持系统补丁及时得到更新。
  - 恶意代码防范
    - 应安装防恶意代码软件，并及时更新防恶意代码软件版本和恶意代码库；
    - 主机防恶意代码产品应具有与网络防恶意代码产品不同的恶意代码库；
    - 应支持防恶意代码的统一管理。
  - 资源控制
    - 应通过设定终端接入方式、网络地址范围等条件限制终端登录；
    - 应根据安全策略设置登录终端的操作超时锁定；
    - 应对重要服务器进行监视，包括监视服务器的CPU、硬盘、内存、网络等资源的使用情况；
    - 应限制单个用户对系统资源的最大或最小使用限度；
    - 应能够对系统的服务水平降低到预先规定的最小值进行检测和报警。

数据本身的安全，主要从应用安全、数据库安全采取措施:

- 应用安全
  - 身份鉴别
    - 应提供专用的登录控制模块对登录用户进行身份标识和鉴别；
    - 应对同一用户采用两种或两种以上组合的鉴别技术实现用户身份鉴别；
    - 应提供用户身份标识唯一和鉴别信息复杂度检查功能，保证应用系统中不存在重复用户身份标识，身份鉴别信息不易被冒用；
    - 应提供登录失败处理功能，可采取结束会话、限制非法登录次数和自动退出等措施；
    - 应启用身份鉴别、用户身份标识唯一性检查、用户身份鉴别信息复杂度检查以及登录失败处理功能，并根据安全策略配置相关参数。
  - 访问控制
    - 应提供访问控制功能，依据安全策略控制用户对文件、数据库表等客体的访问；
    - 访问控制的覆盖范围应包括与资源访问相关的主体、客体及它们之间的操作；
    - 应由授权主体配置访问控制策略，并严格限制默认帐户的访问权限；
    - 应授予不同帐户为完成各自承担任务所需的最小权限，并在它们之间形成相互制约的关系。
    - 应具有对重要信息资源设置敏感标记的功能；
    - 应依据安全策略严格控制用户对有敏感标记重要信息资源的操作；
  - 安全审计
    - 应提供覆盖到每个用户的安全审计功能，对应用系统重要安全事件进行审计；
    - 应保证无法单独中断审计进程，无法删除、修改或覆盖审计记录；
    - 审计记录的内容至少应包括事件的日期、时间、发起者信息、类型、描述和结果等；
    - 应提供对审计记录数据进行统计、查询、分析及生成审计报表的功能。
  - 剩余信息保护
    - 应保证用户鉴别信息所在的存储空间被释放或再分配给其他用户前得到完全清除，无论这些信息是存放在硬盘上还是在内存中；
    - 应保证系统内的文件、目录和数据库记录等资源所在的存储空间被释放或重新分配给其他用户前得到完全清除。
  - 通信完整性
    - 应采用密码技术（ssl，https 协议）保证通信过程中数据的完整性。
  - 通信保密性
    - 在通信双方建立连接之前，应用系统应利用密码技术进行会话初始化验证；
    - 应对通信过程中的整个报文或会话过程进行加密。
  - 抗抵赖
    - 应具有在请求的情况下为数据原发者或接收者提供数据原发证据的功能；
    - 应具有在请求的情况下为数据原发者或接收者提供数据接收证据的功能。
  - 软件容错
    - 应提供数据有效性检验功能，保证通过人机接口输入或通过通信接口输入的数据格式或长度符合系统设定要求；
    - 应提供自动保护功能，当故障发生时自动保护当前所有状态，保证系统能够进行恢复。
  - 资源控制
    - 当应用系统的通信双方中的一方在一段时间内未作任何响应，另一方应能够自动结束会话；
    - 应能够对系统的最大并发会话连接数进行限制；
    - 应能够对单个帐户的多重并发会话进行限制；
    - 应能够对一个时间段内可能的并发会话连接数进行限制；
    - 应能够对一个访问帐户或一个请求进程占用的资源分配最大限额和最小限额；
    - 应能够对系统服务水平降低到预先规定的最小值进行检测和报警；
    - 应提供服务优先级设定功能，并在安装后根据安全策略设定访问帐户或请求进程的优先级，根据优先级分配系统资源。
  - 针对各自安全漏洞采取技术措施
    - SQL 注入，就是通过把SQL命令插入到Web表单提交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令。通过以下方式解决：1) 对用户的输入进行校验，可以通过正则表达式，或限制长度；对单引号和双"-"进行转换等。2) 永远不要使用动态拼装sql，可以使用参数化的sql或者直接使用存储过程进行数据查询存取。3) 永远不要使用管理员权限的数据库连接，为每个应用使用单独的权限有限的数据库连接。4) 不要把机密信息直接存放，加密或者hash掉密码和敏感的信息。5) 应用的异常信息应该给出尽可能少的提示，最好使用自定义的错误信息对原始错误信息进行包装。 6) sql注入的检测方法一般采取辅助软件或网站平台来检测，软件建议采用 IBM 出品的 AppScan平台检测工具，可以有效的防御SQL注入，XSS攻击。
    - 发送敏感信息时，始终使用 SSL 和 POST(主体)参数。
    - 预防跨站点攻击，即Cross Site Script Execution(通常简写为XSS)是指攻击者利用网站程序对用户输入过滤不足，输入可以显示在页面上对其他用户造成影响的HTML代码，从而盗取用户资料、利用用户身份进行某种动作或者对访问者进行病毒侵害的一种攻击方式。1)通过采用安全框架 2) 浏览器 cookie设置为HttpOnly属性 3) web服务器设置httpOnly 4) 对用户输入进行严格检查，是否包含<、>、‘、“等危险字符，如果包含要考虑对这些字符进行过滤或转码。一般是在web应用中配置过滤器统一对所有输入数据进行过滤。
  - 敏感数据安全管理

    例如敏感数据和能定位到个人的数据（如身份证号、家庭住址、手机号码等）均需加密存储。

    - 脱敏处理及结果追溯。通过专业的数据脱敏系统能够实现对各类业务场景下的数据脱敏要求，有日志、有报告，可审计、可追溯，全面应对监管机构的脱敏检查及举证。
    - 敏感数据清单化管理。通过数据梳理技术对数据清单中的敏感数据进行自动发现和标识，形成敏感数据清单，这能够极大提升开发测试环境中的敏感数据安全管理水平，面对监管要求提供严谨依据。
    - 高效自动的敏感数据管理。数据梳理系统与脱敏系统需要具备高度的自动化能力，能够与用户工作流程完美融合，实现数据梳理与脱敏任务的自动下发与高效执行。
    - 脱敏结果可用性。应对不同的开发测试需求，需要考虑脱敏后的数据质量能否满足工作需求，对于不同数据类型采用不同的脱敏算法，并且保证脱敏结果高仿真，保持源数据特征，不影响业务使用。

- 数据安全及备份恢复
  - 数据完整性
    - 应能够检测到系统管理数据、鉴别信息和重要业务数据在传输过程中完整性受到破坏，并在检测到完整性错误时采取必要的恢复措施；
    - 应能够检测到系统管理数据、鉴别信息和重要业务数据在存储过程中完整性受到破坏，并在检测到完整性错误时采取必要的恢复措施。
  - 数据保密性
    - 应采用加密或其他有效措施实现系统管理数据、鉴别信息和重要业务数据传输保密性；
    - 应采用加密或其他保护措施实现系统管理数据、鉴别信息和重要业务数据存储保密性。
  - 备份和恢复
    - 应提供本地数据备份与恢复功能，完全数据备份至少每天一次，备份介质场外存放；
    - 应提供异地数据备份功能，利用通信网络将关键数据定时批量传送至备用场地；
    - 应采用冗余技术设计网络拓扑结构，避免关键节点存在单点故障；
    - 应提供主要网络设备、通信线路和数据处理系统的硬件冗余，保证系统的高可用性。

同时也从管理上制定安全管理制度

- 安全管理制度
  - 管理制度
    - 应制定信息安全工作的总体方针和安全策略，说明机构安全工作的总体目标、范围、原则和安全框架等；
    - 应对安全管理活动中的各类管理内容建立安全管理制度；
    - 应对要求管理人员或操作人员执行的日常管理操作建立操作规程；
    - 应形成由安全策略、管理制度、操作规程等构成的全面的信息安全管理制度体系。
  - 制定和发布
    - 应指定或授权专门的部门或人员负责安全管理制度的制定；
    - 安全管理制度应具有统一的格式，并进行版本控制；
    - 应组织相关人员对制定的安全管理制度进行论证和审定；
    - 安全管理制度应通过正式、有效的方式发布；
    - 安全管理制度应注明发布范围，并对收发文进行登记。
  - 评审和修订
    - 信息安全领导小组应负责定期组织相关部门和相关人员对安全管理制度体系的合理性和适用性进行审定；
    - 应定期或不定期对安全管理制度进行检查和审定，对存在不足或需要改进的安全管理制度进行修订。
- 安全管理机构
  - 岗位设置
    - 应设立信息安全管理工作的职能部门，设立安全主管、安全管理各个方面的负责人岗位，并定义各负责人的职责；
    - 应设立系统管理员、网络管理员、安全管理员等岗位，并定义各个工作岗位的职责；
    - 应成立指导和管理信息安全工作的委员会或领导小组，其最高领导由单位主管领导委任或授权；
    - 应制定文件明确安全管理机构各个部门和岗位的职责、分工和技能要求。
  - 人员配备
    - 应配备一定数量的系统管理员、网络管理员、安全管理员等；
    - 应配备专职安全管理员，不可兼任；
    - 关键事务岗位应配备多人共同管理。
  - 授权和审批
    - 应根据各个部门和岗位的职责明确授权审批事项、审批部门和批准人等；
    - 应针对系统变更、重要操作、物理访问和系统接入等事项建立审批程序，按照审批程序执行审批过程，对重要活动建立逐级审批制度；
    - 应定期审查审批事项，及时更新需授权和审批的项目、审批部门和审批人等信息；
    - 应记录审批过程并保存审批文档。
  - 沟通和合作
    - 应加强各类管理人员之间、组织内部机构之间以及信息安全职能部门内部的合作与沟通，定期或不定期召开协调会议，共同协作处理信息安全问题；
    - 应加强与兄弟单位、公安机关、电信公司的合作与沟通；
    - 应加强与供应商、业界专家、专业的安全公司、安全组织的合作与沟通；
    - 应建立外联单位联系列表，包括外联单位名称、合作内容、联系人和联系方式等信息；
    - 应聘请信息安全专家作为常年的安全顾问，指导信息安全建设，参与安全规划和安全评审等。
  - 审核和检查
    - 安全管理员应负责定期进行安全检查，检查内容包括系统日常运行、系统漏洞和数据备份等情况；
    - 应由内部人员或上级单位定期进行全面安全检查，检查内容包括现有安全技术措施的有效性、安全配置与安全策略的一致性、安全管理制度的执行情况等；
    - 应制定安全检查表格实施安全检查，汇总安全检查数据，形成安全检查报告，并对安全检查结果进行通报；
    - 应制定安全审核和安全检查制度规范安全审核和安全检查工作，定期按照程序进行安全审核和安全检查活动。


### 2.5.2 数据采集的重点与难点

- 数据采集标准

  为了得到高质量的数据，统一数据格式、数据信息标准是数据采集工作的基础。为了落实卫生信息标准，实现医疗信息的规范化，国家相继颁发了《电子病历共享文档规范》《电子病历与医院信息平台标准符合性测试规范》《电子健康档案与区域卫生信息平台标准符合性测试规范》（总共包含57项卫生行业标准）等一系列卫生信息标准，各级医疗机构和企业在设计开发和采购医疗信息系统时均应严格执行上述标准。数据信息标准是实现数据互通、信息共享的基础，也应该被视为医疗信息化建设的重要组成部分。同时也要转变观念，开放共享卫生健康信息。建立卫生信息共享服务平台，促进卫生信息资源的有效整合，实现各种信息资源的无缝对接，促进医疗卫生信息的共享，实现各级医疗机构的数据互通。

  在数据采集工作中，严格执行国家和行业相关标准和程序，符合业务应用技术标准和管理规范，做到标准统一、术语规范、内容准确，保证服务和管理对象在系统中身份标识唯一、基本数据项一致，所采集的信息应当严格实行信息复核终审程序，为下一步做好数据质量管理做好准备。

  数据采集信息平台技术规范符合《基于健康档案的区域卫生信息平台技术规范》、《基于电子病历的医院信息平台技术规范》，文档格式标准符合《健康档案共享文档规范》、《电子病历共享文档规范》，数据元和代码标准符合《城乡居民健康档案基本数据集》、《电子病历基本数据集》、《卫生信息数据元目录》、《卫生信息数据元值域代码》。在数据层面基于卫生信息数据元和代码标准，在技术层面以HL7 CDA格式来表达。

- 数据采集方式

  ETL（extract提取、transform转换、load加载）。ETL负责将分散的、异构数据源中的数据如关系数据、平面数据文件等抽取到临时中间层后，进行清洗、转换、集成，最后加载到数据仓库或数据集市中，成为联机分析处理、数据挖掘提供决策支持的数据。

  ETL是构建数据仓库的重要的一环，用户从数据源抽取所需的数据，经过数据清洗，最终按照预先定义好的数据仓库模型，将数据加载到数据仓库中。其定义域来源也不下于十几年，技术发展也应相当成熟。可乍眼一看，似乎并没有什么技术可言，也没有什么深奥之处，但在实际的项目中，却常常在这个环节上耗费太多的人力，而在后期的维护上，往往更费脑筋。导致上面的原因，往往是在项目初期没有正确的估计ETL的工作，没有认真的考虑其与工具支撑有很大的关系。

  在做ETL产品选型的时候，任然必不可少的要面临四点（成本、人员经验、案例和技术支持）来考量。在做ETL的过程中，也随之产生于一些ETL工具，如Datastage、Powercenter、ETLAutomation。而在实际ETL工具应用的对比上，对元数据的支持、对数据质量的支持、维护的方便性、定制开发功能的支持等方面是我们选择的切入点。一个项目，从数据源到最终目标表，多则达上百个ETL过程，少则也十几个。这些过程之间的依赖关系、出错控制以及恢复的流程处理，都是工具需要重点考虑。

  ETL是将业务系统的数据经过抽取、清洗转换之后加载到数据仓库的过程，目的是将企业中的分散、零乱、标准不统一的数据整合到一起，为企业的决策提供分析依据。 ETL是BI项目重要的一个环节。 通常情况下，在项目中ETL会花掉整个项目至少1/3的时间,ETL设计的好坏直接关接到BI项目的成败。

  ETL的设计分三部分：数据抽取、数据的清洗转换、数据的加载。在设计ETL的时候我们也是从这三部分出发。数据的抽取是从各个不同的数据源抽取到ODS(Operational Data Store，操作型数据存储)中——这个过程也可以做一些数据的清洗和转换)，在抽取的过程中需要挑选不同的抽取方法，尽可能的提高ETL的运行效率。ETL三个部分中，花费时间最长的是“T”(Transform，清洗、转换)的部分，一般情况下这部分工作量是整个ETL的2/3。数据的加载一般在数据清洗完了之后直接写入DW(Data Warehousing，数据仓库)中去。

  ETL的实现有多种方法，常用的有三种。一种是借助ETL工具(如Oracle的OWB、SQL Server 2000的DTS、SQL Server2005的SSIS服务、Informatic等)实现，一种是SQL方式实现，另外一种是ETL工具和SQL相结合。前两种方法各有各的优缺点，借助工具可以快速的建立起ETL工程，屏蔽了复杂的编码任务，提高了速度，降低了难度，但是缺少灵活性。SQL的方法优点是灵活，提高ETL运行效率，但是编码复杂，对技术要求比较高。第三种是综合了前面二种的优点，会极大地提高ETL的开发速度和效率。

  - 数据的抽取（Extract）

    这一部分需要在调研阶段做大量的工作，首先要搞清楚数据是从几个业务系统中来,各个业务系统的数据库服务器运行什么DBMS,是否存在手工数据，手工数据量有多大，是否存在非结构化的数据等等，当收集完这些信息之后才可以进行数据抽取的设计。

    对于与存放DW的数据库系统相同的数据源处理方法。这一类数据源在设计上比较容易。一般情况下，DBMS(SQLServer、Oracle)都会提供数据库链接功能，在DW数据库服务器和原业务系统之间建立直接的链接关系就可以写Select 语句直接访问。

    对于与DW数据库系统不同的数据源的处理方法。对于这一类数据源，一般情况下也可以通过ODBC的方式建立数据库链接——如SQL Server和Oracle之间。如果不能建立数据库链接，可以有两种方式完成，一种是通过工具将源数据导出成.txt或者是.xls文件，然后再将这些源系统文件导入到ODS中。另外一种方法是通过程序接口来完成。

    对于文件类型数据源(.txt,.xls)，可以培训业务人员利用数据库工具将这些数据导入到指定的数据库，然后从指定的数据库中抽取。或者还可以借助工具实现。

    增量更新的问题。对于数据量大的系统，必须考虑增量抽取。一般情况下，业务系统会记录业务发生的时间，我们可以用来做增量的标志,每次抽取之前首先判断ODS中记录最大的时间，然后根据这个时间去业务系统取大于这个时间所有的记录。利用业务系统的时间戳，一般情况下，业务系统没有或者部分有时间戳。

  - 数据的清洗转换（Cleaning、Transform）

    一般情况下，数据仓库分为ODS、DW两部分。通常的做法是从业务系统到ODS做清洗，将脏数据和不完整数据过滤掉，在从ODS到DW的过程中转换，进行一些业务规则的计算和聚合。

    数据清洗。数据清洗的任务是过滤那些不符合要求的数据，将过滤的结果交给业务主管部门，确认是否过滤掉还是由业务单位修正之后再进行抽取。

    不符合要求的数据主要是有不完整的数据、错误的数据、重复的数据三大类。

    (1)不完整的数据：这一类数据主要是一些应该有的信息缺失，如供应商的名称、分公司的名称、客户的区域信息缺失、业务系统中主表与明细表不能匹配等。对于这一类数据过滤出来，按缺失的内容分别写入不同Excel文件向客户提交，要求在规定的时间内补全。补全后才写入数据仓库。

    (2)错误的数据：这一类错误产生的原因是业务系统不够健全，在接收输入后没有进行判断直接写入后台数据库造成的，比如数值数据输成全角数字字符、字符串数据后面有一个回车操作、日期格式不正确、日期越界等。这一类数据也要分类，对于类似于全角字符、数据前后有不可见字符的问题，只能通过写SQL语句的方式找出来，然后要求客户在业务系统修正之后抽取。日期格式不正确的或者是日期越界的这一类错误会导致ETL运行失败，这一类错误需要去业务系统数据库用SQL的方式挑出来，交给业务主管部门要求限期修正，修正之后再抽取。

    (3)重复的数据：对于这一类数据——特别是维表中会出现这种情况——将重复数据记录的所有字段导出来，让客户确认并整理。

    数据清洗是一个反复的过程，不可能在几天内完成，只有不断的发现问题，解决问题。对于是否过滤，是否修正一般要求客户确认，对于过滤掉的数据，写入Excel文件或者将过滤数据写入数据表，在ETL开发的初期可以每天向业务单位发送过滤数据的邮件，促使他们尽快地修正错误,同时也可以做为将来验证数据的依据。数据清洗需要注意的是不要将有用的数据过滤掉，对于每个过滤规则认真进行验证，并要用户确认。

    数据转换。数据转换的任务主要进行不一致的数据转换、数据粒度的转换，以及一些商务规则的计算。

    (1)不一致数据转换：这个过程是一个整合的过程，将不同业务系统的相同类型的数据统一，比如同一个供应商在结算系统的编码是XX0001,而在CRM中编码是YY0001，这样在抽取过来之后统一转换成一个编码。

    (2)数据粒度的转换：业务系统一般存储非常明细的数据，而数据仓库中数据是用来分析的，不需要非常明细的数据。一般情况下，会将业务系统数据按照数据仓库粒度进行聚合。

    (3)商务规则的计算：不同的企业有不同的业务规则、不同的数据指标，这些指标有的时候不是简单的加加减减就能完成，这个时候需要在ETL中将这些数据指标计算好了之后存储在数据仓库中，以供分析使用。

- 数据采集监控

  ETL日志分为三类。

  - 一类是执行过程日志，这一部分日志是在ETL执行过程中每执行一步的记录，记录每次运行每一步骤的起始时间，影响了多少行数据，流水账形式。
  - 一类是错误日志，当某个模块出错的时候写错误日志，记录每次出错的时间、出错的模块以及出错的信息等。
  - 第三类日志是总体日志，只记录ETL开始时间、结束时间是否成功信息。如果使用ETL工具,ETL工具会自动产生一些日志，这一类日志也可以作为ETL日志的一部分。

  记录日志的目的是随时可以知道ETL运行情况，如果出错了，可以知道哪里出错。

  - 警告发送。如果ETL出错了，不仅要形成ETL出错日志，而且要向系统管理员发送警告。发送警告的方式多种，一般常用的就是给系统管理员发送邮件，并附上出错的信息，方便管理员排查错误。

- 总结

  ETL是项目数据采集的关键部分，也是一个长期的过程，只有不断的发现问题并解决问题，才能使ETL运行效率更高，为项目后期开发提供准确与高效的数据。

  说大了，ETL是数据整合解决方案，说小了，就是倒数据的工具。回忆一下工作这么长时间以来，处理数据迁移、转换的工作倒还真的不少。但是那些工作基本上是一次性工作或者很小数据量。可是在数据仓库系统中，ETL上升到了一定的理论高度，和原来小打小闹的工具使用不同了。究竟什么不同，从名字上就可以看到，人家已经将倒数据的过程分成3个步骤，E、T、L分别代表抽取、转换和装载。

  其实ETL过程就是数据流动的过程，从不同的数据源流向不同的目标数据。

  ETL有几个特点，一是数据同步，它不是一次性倒完数据就拉到，它是经常性的活动，按照固定周期运行的，甚至现在还有人提出了实时ETL的概念。二是数据量，一般都是巨大的，值得你将数据流动的过程拆分成E、T和L。

  现在有很多成熟的工具提供ETL功能，且不说他们的好坏。从应用角度来说，ETL的过程其实不是非常复杂，这些工具给数据仓库工程带来和很大的便利性，特别是开发的便利和维护的便利。但另一方面，开发人员容易迷失在这些工具中。举个例子，VB是一种非常简单的语言并且也是非常易用的编程工具，上手特别快，但是真正VB的高手有多少？微软设计的产品通常有个原则是“将使用者当作傻瓜”，在这个原则下，微软的东西确实非常好用，但是对于开发者，如果你自己也将自己当作傻瓜，那就真的傻了。ETL工具也是一样，这些工具为我们提供图形化界面，让我们将主要的精力放在规则上，以期提高开发效率。从使用效果来说，确实使用这些工具能够非常快速地构建一个job来处理某个数据，不过从整体来看，并不见得他的整体效率会高多少。问题主要不是出在工具上，而是在设计、开发人员上。他们迷失在工具中，没有去探求ETL的本质。可以说这些工具应用了这么长时间，在这么多项目、环境中应用，它必然有它成功之处，它必定体现了ETL的本质。如果我们不透过表面这些工具的简单使用去看它背后蕴涵的思想，最终我们作出来的东西也就是一个个独立的job，将他们整合起来仍然有巨大的工作量。大家都知道“理论与实践相结合”，如果在一个领域有所超越，必须要在理论水平上达到一定的高度.

### 2.5.3 数据库设计的重点与难点

- 数据库选型

  - 稳定可靠(High-Availability)。数据库保存的是企业最重要的数据，是企业应用的核心，稳定可靠的数据库可以保证企业的应用常年运行，而不会因为数据库的宕机而遭受损失。企业的信息化可以促进生产力，但如果选择了不稳定产品，经常影响业务生产的正常运营，则实际效果很可能是拖了企业的后退。无论是计划中（数据库维护等正常工作）还是意外的宕机都将给企业带来巨大的损失，这意味着企业要减低收入、要降低生产力、要丢失客户、要在激烈的企业竞争中丢失信心。信息系统的稳定可靠是由多方面的因素构成的，包括网络、主机、操作系统、数据库以及应用软件等几方面，这些因素互相之间又有一定的依赖关系，因此，在企业信息化的选型中要通盘考虑这些问题。在数据库方面主要看数据库要具备灾难恢复、系统错误恢复、人为操作错误恢复等功能，同时要尽量降低数据库的计划内维护宕机时间。

  - 可扩展(High-Scalability)。企业的应用是不断深入和扩展的，数据量和单位时间的事务处理量都会逐渐增加。如果要求企业购置一套信息系统足以满足未来若干年发展的需要显然是不恰当的，因为这实际意味着企业要多花很多钱而不能发挥信息设备的最大效能，造成资源的浪费。比较好的解决办法就是企业先购置一套配置较低，功能适用的系统，当未来业务有需要时可以方便的对系统进行扩展，使系统的处理能力逐步增加满足业务处理的需求。落实到数据库就是要选择具有良好的伸缩性及灵活的配置功能的产品，无论是主机系统的内存或硬盘方面的扩展还是集群系统的扩展，都能够被数据库利用，从而提高系统的处理能力。

  - 安全性(Security)。数据库的安全性是指保护数据库以防止不合法的使用造成的数据泄露、更改或破坏。安全性问题不是数据库系统独有的，所有计算机系统都有这个问题。只是在数据库系统中保存着大量重要的数据，而且为许多最终用户共享使用，从而安全问题更为突出。系统安全保护措施是否有效是数据库系统的重要指标之一。 数据库的安全控制主要通过用户标识与鉴别、存取控制、视图机制、审计、数据加密等机制完成。

  - 丰富的开发工具。无论是优秀的硬件平台还是功能强大的数据库管理系统，都不能直接解决最终用户的应用问题，企业信息化的工作也要落实到开发或购买适合企业自身管理的应用软件。目前流行的数据库管理系统大都遵循统一的接口标准，所以大部分的开发工具都可以面向多种数据库的应用开发。当然，数据库厂商通常都有自己的开发工具，例如SYBASE公司的PowerBuilder，Oracle公司的Developer2000，以及Ms的VisualStudio。这些开发工具各有利弊，但无疑选择和数据库同一个厂商的产品会更有利于应用软件的开发以及将来得到统一的技术支持。

  - 服务质量。在现今信息高度发达的竞争中，数据库厂商完全靠产品质量打动用户的年代已不复存在，各数据库产品在质量方面的差距逐渐缩小，而用户选择产品的一个重要因素就是定位在厂家的技术服务方面。因为在你购买了数据库系统之后，你面临着复杂的软件开发，数据库的维护，数据库产品的升级等等，你需要得到数据库厂商的培训，各种方式的技术支持（电话、用户现场）和咨询。数据库厂家的服务质量的好坏将直接影响到企业信息化建设的工作。

  基于以上，我们在系统设计时，推荐采用 Oracle 或者 MsSqlServer 这样有大厂商保障的企业级数据库。

- 数据库逻辑设计难点和重点

  糟糕的数据库设计：数据冗余、存储空间浪费；数据更新和插入的异常；程序性能差。良好的数据库设计：节省数据的存储空间；能够保证数据的完整性；方便进行数据库应用系统的开发。

  为了能得到良好的数据库设计，就必须在系统项目开发中做好以下几点:

  - 需求分析阶段：1）分析业务和数据处理需求,收集信息。2）与该系统有关人员进行交流、座谈，充分了解用户需求，理解数据库需要完成的任务。3）标识数据库要管理的关键对象或实体。4）标识每个实体需要存储的详细信息。5）标识实体之间的关系（Relationship）
  - 概要设计阶段：设计数据库的模型图，确认需求信息的正确和完整。采用设计工具(visio) 绘制E-R图，用二维表的形式表示实体和实体间联系的数据模型即关系模式。
  - 详细设计阶段：应用三大范式审核数据库结构。1）第一范式的目标是确保每列的原子性，如果每列都是不可再分的最小数据单元（也称为最小的原子单元），则满足第一范式（1NF）。2）第二范式要求每个表只描述一件事情。3）如果一个关系满足2NF，并且除了主键以外的其他列都不传递依赖于主键列，则满足第三范式（3NF）。
  - 代码编写阶段：物理实现数据库，编码实现应用。规范化和性能的关系：1）为满足某种商业目标，数据库性能比规范化数据库更重要。2）在数据规范化同时，要综合考虑数据库的性能。
  - 注意，从设计原则上讲，为了保证数据库存储合理，尽量减少冗余字段，但有的场景下为了得到高并发，适当存放冗余还是允许的，并且通过方案比较，还是值得采用。

- 数据库运行设计的难点和重点

  上线系统最担心的就是数据库出现瓶颈，如何发现性能问题，通过什么定位，是数据库设计时需考虑的问题。

  - 数据库级快照。1）连接数信息：applications connected currently，appls executing in db manager currently。2）锁信息：锁总数，锁等待数量，锁等待总时间，当前数据库锁列表占用内存，死锁次数，锁升级次数，锁超时次数。3）排序信息：排序是CPU杀手，过多的排序会造成CPU的极大消耗；4）排序溢出是说，如果排序堆无法容纳排序数据，就会被溢出到临时空间；排序是一种状态，根源在SQL语句；5）数据索引I/O信息：逻辑读数据库向缓冲池请求的次数 逻辑读越多，需要的物理I/O就越少。6）物理读 如果请求的数据页不在缓冲池，需要从磁盘中读取数据页的次数。7）吞吐量或事务信息：提交/回滚事务数，执行动态和静态语句次数，增删改查次数( rows read / rows selected ) 是一个非常重要的性能指标，它表示为了检索一行数据需要读取多少行，该值越大，表示代价越高，需要的I/O越多，可调优的余地越大。8）事务日志信息：日志I/O在很大程度上会影响数据库整体的性能
  - 应用程序监控。通过应用程序监控工具可以细化到某条特定的语句，统计出SQL 执行的效率。
  - 动态SQL监控。通过数据库提供的监控，统计出 SQL执行次数，总共读的行数，消耗的CPU，逻辑物理读数量，排序数量等。

  数据库运行时需关注的几点

  - 临时表的创建和维护。在做复杂业务分析时，一个存储过程也会用到很多临时表（存储业务分析某一步的中间结果），这些表的数据经常变化（每个周期都会被清空再装入），还需要和别的表做关联，如果有大量的临时表存在，势必会占有大量的存储空间，所以必须有方式及时清除临时表，可以通过应用系统的自动任务或者数据库提供的定时任务做这些工作。
  - 临时表空间维护。数据库在排序、表关联等处理时会用到系统临时表空间，如果表空间不够就会影响数据库性能。所以必须通过查看数据库配置、日志，及时调整临时表空间大小。
  - 表容量维护。对一些增长明显的业务表，在系统设计时要考虑分表存放，采用分区表，建议以日期作为分区键，按分区的周期拆离分区。
  - 尽量采用读写分离数据库模式，解决单点数据库压力大问题。
  - 应用层面尽量采用缓存，减少数据库访问机会，特别是在多用户高并发的场景。

### 2.5.4 数据挖掘及展示的重点与难点

数据孤岛、零散数据等现象一直是企业大数据应用过程中所常见的问题，当数据以及数据来源增加过快时，不同数据之间的打通就成了最大的困难，有时这对于传统企业来说更是尤为困难。而数据关系挖掘作为解决数据孤岛等难题的手段之一，可以有效的帮助企业将多样化的数据进行统一存储并挖掘出其中隐藏的价值，目前在公安、电信、金融、医疗等行业中的应用也正变得愈加广泛。

